{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9870e756",
   "metadata": {
    "papermill": {
     "duration": 0.01055,
     "end_time": "2025-11-30T08:11:03.364800",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.354250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üêù InsightSwarm: Autonomous Enterprise Data Analytics\n",
    "## ü§ñ Google AI Agents Intensive - Capstone Project (Enterprise Track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb9d77",
   "metadata": {
    "papermill": {
     "duration": 0.008777,
     "end_time": "2025-11-30T08:11:03.384382",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.375605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìñ Project Overview\n",
    "InsightSwarm is an autonomous, production-grade multi-agent system designed to revolutionize how enterprises interact with their data. Built using the Google Agent Development Kit (ADK) and powered by Gemini 2.5, InsightSwarm replaces static dashboards with an intelligent, memory-aware workforce that can ingest raw data, extract strategic insights, and generate visual reports without human intervention.\n",
    "\n",
    "Unlike standard chatbots, InsightSwarm features Long-Term Institutional Memory, Self-Correcting Code Generation, and a full AgentOps Suite (Safety, Observability, FinOps) to ensure reliable deployment in enterprise environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2b11e",
   "metadata": {
    "papermill": {
     "duration": 0.009415,
     "end_time": "2025-11-30T08:11:03.402623",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.393208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üéØ Problem Statement\n",
    "In the modern enterprise, data analysis is a bottleneck.\n",
    "\n",
    "Data Silos: Engineers, Analysts, and Managers work in disconnected loops.\n",
    "\n",
    "Corporate Amnesia: Agents usually \"forget\" context between sessions. If an analyst discovers a trend in Q3, the agent forgets it by Q4.\n",
    "\n",
    "Fragility: Standard AI code generators often fail when libraries change or data is messy, requiring human debugging.\n",
    "\n",
    "Safety Risks: Deploying LLMs on private data risks PII leakage and hallucinations.\n",
    "\n",
    "# üí° The Solution\n",
    "InsightSwarm solves these problems via a \"Memory-Augmented Hive Architecture\":\n",
    "\n",
    "Observe: It scans SQL databases and historical context (Memory Bank).\n",
    "\n",
    "Think: It plans analysis strategies aligned with corporate goals (RAG).\n",
    "\n",
    "Act: It autonomously writes/fixes SQL and Python code to visualize data.\n",
    "\n",
    "Remember: It extracts key findings from every session and consolidates them into a persistent SQLite Knowledge Graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627256c2",
   "metadata": {
    "papermill": {
     "duration": 0.010382,
     "end_time": "2025-11-30T08:11:03.421821",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.411439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèóÔ∏è System Architecture\n",
    "InsightSwarm utilizes a Hierarchical Hybrid Architecture, combining Sequential workflows for reliability and Loop patterns for quality control.\n",
    "\n",
    "## üß© Agent Topology\n",
    "The Orchestrator (Root): Manages the hand-off between specialized agents and injects Long-Term Memory into the context window.\n",
    "\n",
    "Senior Data Engineer: Specialized in SQL generation, schema understanding, and data cleaning.\n",
    "\n",
    "Strategic Analyst: Specialized in RAG (retrieving business KPIs) and synthesizing data trends against historical memory.\n",
    "\n",
    "Visualization Loop (Self-Correcting): A nested sub-system containing:\n",
    "\n",
    "VizExpert: Generates Python plotting code (Matplotlib/Seaborn).\n",
    "\n",
    "DesignCritic: Reviews charts for brand compliance and errors. If a chart fails, the loop retries automatically.\n",
    "\n",
    "## üîÑ Core Components\n",
    "Google ADK: The backbone for agent definition, session management, and runtime.\n",
    "\n",
    "Gemini 2.5 Flash-Lite: The reasoning engine, optimized for speed and cost efficiency.\n",
    "\n",
    "Active Memory Bank: A custom SQLite-based system that performs \"Extraction\" and \"Consolidation\" of insights.\n",
    "\n",
    "Guardrails Layer: A pre-flight interceptor that scrubs PII and blocks malicious prompts using Regex/Logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e897e63",
   "metadata": {
    "papermill": {
     "duration": 0.009926,
     "end_time": "2025-11-30T08:11:03.442420",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.432494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚öôÔ∏è Technical Implementation\n",
    "## 1. Intelligent Tooling\n",
    "We moved beyond simple function calling to Robust Engineering:\n",
    "\n",
    "Self-Healing Tools: The run_local_analytics tool captures Python tracebacks and feeds them back to the LLM, allowing the agent to fix its own syntax errors.\n",
    "\n",
    "Caching Layer: A @cache_result decorator reduces latency and cost by storing results of expensive SQL or RAG queries.\n",
    "\n",
    "## 2. Context Engineering (Memory)\n",
    "InsightSwarm implements the \"Active Memory\" pattern described in the Google Whitepapers:\n",
    "\n",
    "Extraction: After every run, the system analyzes the conversation to find new facts (e.g., \"West region performance is down\").\n",
    "\n",
    "Consolidation: New facts are merged into the memory_bank table, ensuring the agent gets smarter over time.\n",
    "\n",
    "Retrieval: Before every run, relevant historical context is injected into the System Prompt.\n",
    "\n",
    "## 3. AgentOps & Observability\n",
    "The system includes a full operational suite:\n",
    "\n",
    "Enterprise Logger: Structured SQL logging for all traces (Inputs, Outputs, Tool Calls).\n",
    "\n",
    "FinOps Dashboard: Calculates token usage and estimates cost per session ($0.00001 precision).\n",
    "\n",
    "CI/CD Smoke Tests: A pre-deployment script that verifies DB connectivity and tool integrity before runtime.\n",
    "\n",
    "RAI Scanner: An automated safety check for toxic language and bias in the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfe5c5",
   "metadata": {
    "papermill": {
     "duration": 0.00914,
     "end_time": "2025-11-30T08:11:03.460941",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.451801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üåä Data Flow Pipeline\n",
    "1. Ingestion: User query is sanitized by SecurityGuard.\n",
    "\n",
    "2. Context Loading: MemoryManager fetches relevant history from SQLite.\n",
    "\n",
    "3. Engineering: DataEngineer queries sales_data DB via SQL.\n",
    "\n",
    "4. Analysis: Analyst compares results against STRATEGY_DOCS (RAG).\n",
    "\n",
    "5. Visualization: VizExpert drafts code -> DesignCritic reviews -> VizExpert fixes -> Chart Generated.\n",
    "\n",
    "6. Delivery: Final report + Image presented to user.\n",
    "\n",
    "7. Learning: System extracts new insights and updates memory_bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d176d",
   "metadata": {
    "papermill": {
     "duration": 0.008676,
     "end_time": "2025-11-30T08:11:03.478827",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.470151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÇ Repository Structure\n",
    "\n",
    "‚îú‚îÄ‚îÄ insightswarm.ipynb    # Main Application Logic\n",
    "\n",
    "‚îú‚îÄ‚îÄ agent_manifest.json   # Deployment Configuration\n",
    "\n",
    "‚îú‚îÄ‚îÄ Dockerfile            # Production Container Definition\n",
    "\n",
    "‚îú‚îÄ‚îÄ requirements.txt      # Dependency Lockfile\n",
    "\n",
    "‚îú‚îÄ‚îÄ sales_warehouse.db    # Simulation Data & Memory Store\n",
    "\n",
    "‚îî‚îÄ‚îÄ dashboard.png         # Generated Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf63938",
   "metadata": {
    "papermill": {
     "duration": 0.008723,
     "end_time": "2025-11-30T08:11:03.496613",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.487890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß™ Example Usage Scenario\n",
    "## User Query:\n",
    "\n",
    "\"Analyze sales performance in the East region. Compare with our known history and generate a distribution chart.\"\n",
    "\n",
    "## Agent Actions:\n",
    "\n",
    "Memory Retrieval: Recalls that \"East region had supply chain issues in Q3.\"\n",
    "\n",
    "SQL Query: SELECT product, SUM(amount) FROM sales_data WHERE region='East'...\n",
    "\n",
    "Strategic Insight: \"Revenue has recovered since Q3, matching our KPI targets.\"\n",
    "\n",
    "Visualization: Generates a Pie Chart (Self-corrected color scheme to match Corporate Blue #1f77b4).\n",
    "\n",
    "Final Output: Displays chart and strategic summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936af5c",
   "metadata": {
    "papermill": {
     "duration": 0.008985,
     "end_time": "2025-11-30T08:11:03.514587",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.505602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèÜ Key Features Checklist (Capstone Requirements)\n",
    "‚úÖ Multi-Agent System: Implemented SequentialAgent and LoopAgent patterns.\n",
    "\n",
    "‚úÖ Tools: Implemented Custom Tools, RAG Tools, and Plotting Tools.\n",
    "\n",
    "‚úÖ Sessions & Memory: Implemented DatabaseSessionService and a custom Active Memory Bank.\n",
    "\n",
    "‚úÖ Agent Evaluation: Implemented LLM-as-a-Judge for quality scoring.\n",
    "\n",
    "‚úÖ Agent Deployment: Generated valid Dockerfile and requirements.txt for Cloud Run.\n",
    "\n",
    "‚úÖ Security: Implemented Input/Output Guardrails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0759e",
   "metadata": {
    "papermill": {
     "duration": 0.010926,
     "end_time": "2025-11-30T08:11:03.534799",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.523873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üîÆ Future Enhancements\n",
    "Integration with Vertex AI Vector Search for larger memory scales.\n",
    "\n",
    "Adopting Agent-to-Agent (A2A) Protocol to connect with external vendor agents.\n",
    "\n",
    "Real-time Human-in-the-loop approval via Slack integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace304a3",
   "metadata": {
    "papermill": {
     "duration": 0.009169,
     "end_time": "2025-11-30T08:11:03.553114",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.543945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Built with ‚ù§Ô∏è during the Google AI Agents Intensive 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a55aa1",
   "metadata": {
    "papermill": {
     "duration": 0.009295,
     "end_time": "2025-11-30T08:11:03.572070",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.562775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# THE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e93148",
   "metadata": {
    "papermill": {
     "duration": 0.009396,
     "end_time": "2025-11-30T08:11:03.591125",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.581729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 1: Setup & Dependencies\n",
    "* **Purpose**: This is the foundation of the project. It installs necessary external libraries and sets up the environment.\n",
    "\n",
    "* **Key Actions**:\n",
    "\n",
    "    * `!pip install`: Installs `google-adk` (for building agents) and `pydantic` (for data validation), which aren't pre-installed in standard environments.\n",
    "\n",
    "    * **Imports:** Brings in essential Python modules like `sqlite3` (database), `json` (data format), `pandas & numpy` (data manipulation), and `datetime` (time tracking).\n",
    "\n",
    "    * **API Key Setup:** Retrieves your Google API key from Kaggle secrets and configures the environment to use it with the ADK. This is crucial for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1167dd76",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T08:11:03.611440Z",
     "iopub.status.busy": "2025-11-30T08:11:03.611143Z",
     "iopub.status.idle": "2025-11-30T08:12:01.248874Z",
     "shell.execute_reply": "2025-11-30T08:12:01.247532Z"
    },
    "papermill": {
     "duration": 57.658396,
     "end_time": "2025-11-30T08:12:01.258768",
     "exception": false,
     "start_time": "2025-11-30T08:11:03.600372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m‚ö†Ô∏è Error: Set GOOGLE_API_KEY in Secrets.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & DEPENDENCIES ---\n",
    "!pip install -q google-adk pydantic\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from google.genai import types\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.agents import LlmAgent, SequentialAgent\n",
    "from google.adk.tools import FunctionTool\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.apps.app import App, ResumabilityConfig\n",
    "\n",
    "# API Setup\n",
    "try:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"‚úÖ Environment Configured.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Error: Set GOOGLE_API_KEY in Secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23de878",
   "metadata": {
    "papermill": {
     "duration": 0.009979,
     "end_time": "2025-11-30T08:12:01.277565",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.267586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 2: Enterprise Data Infrastructure\n",
    "* **Purpose:** Creates the persistent storage layer for the system. A real enterprise app needs a database, not just memory.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * `init_db()`: Connects to a SQLite database (`enterprise_system.db`) and creates four tables:\n",
    "\n",
    "        * `sales_data`: Holds the raw business data the agents will analyze.\n",
    "\n",
    "        * `traces`: Stores logs of agent actions for observability.\n",
    "        \n",
    "        * `memory_bank`: Stores long-term insights learned by the agents.\n",
    "        \n",
    "        * `eval_scores`: Stores feedback and quality scores.\n",
    "\n",
    "    * `seed_data()`: Populates the `sales_data` table with dummy data so the agents have something to work with immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd8eaa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.300629Z",
     "iopub.status.busy": "2025-11-30T08:12:01.300015Z",
     "iopub.status.idle": "2025-11-30T08:12:01.393745Z",
     "shell.execute_reply": "2025-11-30T08:12:01.392092Z"
    },
    "papermill": {
     "duration": 0.106566,
     "end_time": "2025-11-30T08:12:01.395580",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.289014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database Schema Initialized: Sales, Traces, Memory, Eval.\n",
      "‚úÖ Seeded 200 Sales Records.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 2: ENTERPRISE DATA INFRASTRUCTURE ---\n",
    "\n",
    "DB_NAME = \"enterprise_system.db\"\n",
    "\n",
    "def init_db():\n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        # 1. Business Data (The \"Truth\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS sales_data\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE sales_data (\n",
    "                id INTEGER PRIMARY KEY, date TEXT, region TEXT, \n",
    "                product TEXT, amount REAL, customer_sentiment REAL\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # 2. Observability: Traces (The \"Flight Recorder\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS traces (\n",
    "                trace_id TEXT, timestamp TEXT, agent TEXT, \n",
    "                action TEXT, input TEXT, output TEXT, latency_ms REAL\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # 3. Knowledge: Memory Bank (The \"Brain\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS memory_bank (\n",
    "                id INTEGER PRIMARY KEY, fact TEXT, \n",
    "                confidence FLOAT, last_updated TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # 4. Evaluation: Scorecard (The \"Judge\")\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS eval_scores (\n",
    "                run_id TEXT, criteria TEXT, score INTEGER, reasoning TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "    print(\"‚úÖ Database Schema Initialized: Sales, Traces, Memory, Eval.\")\n",
    "\n",
    "def seed_data():\n",
    "    data = []\n",
    "    regions = ['North', 'South', 'East', 'West']\n",
    "    products = ['SaaS License', 'Cloud Storage', 'Consulting']\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate 200 realistic rows\n",
    "    for _ in range(200):\n",
    "        data.append((\n",
    "            None, datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            np.random.choice(regions), np.random.choice(products),\n",
    "            round(np.random.uniform(1000, 50000), 2),\n",
    "            round(np.random.uniform(1, 10), 1)\n",
    "        ))\n",
    "    \n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        conn.executemany(\"INSERT INTO sales_data VALUES (?,?,?,?,?,?)\", data)\n",
    "    print(\"‚úÖ Seeded 200 Sales Records.\")\n",
    "\n",
    "init_db()\n",
    "seed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df962b66",
   "metadata": {
    "papermill": {
     "duration": 0.009454,
     "end_time": "2025-11-30T08:12:01.414718",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.405264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 3: Safety Guardrails\n",
    "* **Purpose:** Adds a layer of security to prevent malicious use or data leaks.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * `SecurityGuard` Class: A container for safety logic.\n",
    "\n",
    "    * `scan_input`: Checks user prompts for dangerous keywords like \"drop table\" or \"ignore instructions\" (Prompt Injection defense).\n",
    "\n",
    "    * `scrub_pii`: Removes sensitive patterns like email addresses from text before processing (Data Privacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbca8528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.434524Z",
     "iopub.status.busy": "2025-11-30T08:12:01.434229Z",
     "iopub.status.idle": "2025-11-30T08:12:01.441908Z",
     "shell.execute_reply": "2025-11-30T08:12:01.440491Z"
    },
    "papermill": {
     "duration": 0.019876,
     "end_time": "2025-11-30T08:12:01.444152",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.424276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Security Guardrails Active.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: SAFETY GUARDRAILS ---\n",
    "\n",
    "class SecurityGuard:\n",
    "    \"\"\"Enforces safety policies before/after agent execution.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def scan_input(text: str) -> bool:\n",
    "        # Simple regex for prompt injection or sensitive patterns\n",
    "        forbidden = [r\"ignore previous instructions\", r\"system prompt\", r\"drop table\"]\n",
    "        for pattern in forbidden:\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                print(f\"üö® SECURITY ALERT: Blocked malicious input pattern: '{pattern}'\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def scrub_pii(text: str) -> str:\n",
    "        # Mock PII scrubber (hides email addresses)\n",
    "        email_pattern = r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+'\n",
    "        return re.sub(email_pattern, \"[REDACTED_EMAIL]\", text)\n",
    "\n",
    "print(\"‚úÖ Security Guardrails Active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a34a3",
   "metadata": {
    "papermill": {
     "duration": 0.009155,
     "end_time": "2025-11-30T08:12:01.463381",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.454226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 4: Data Contracts\n",
    "* **Purpose:** Defines strict structures for data exchange using Pydantic.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "  * `SalesMetric` & `DashboardSpec`: Classes that define exactly what fields (like `total_revenue` or `chart_type`) are expected. This prevents the LLM from outputting random or malformed data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309ef4a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.482555Z",
     "iopub.status.busy": "2025-11-30T08:12:01.482241Z",
     "iopub.status.idle": "2025-11-30T08:12:01.489446Z",
     "shell.execute_reply": "2025-11-30T08:12:01.488615Z"
    },
    "papermill": {
     "duration": 0.018971,
     "end_time": "2025-11-30T08:12:01.491132",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.472161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Schemas Defined.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: DATA CONTRACTS ---\n",
    "\n",
    "class SalesMetric(BaseModel):\n",
    "    region: str\n",
    "    total_revenue: float\n",
    "    average_sentiment: float\n",
    "\n",
    "class DashboardSpec(BaseModel):\n",
    "    title: str\n",
    "    chart_type: str\n",
    "    x_axis: str\n",
    "    y_axis: str\n",
    "    data_points: List[float]\n",
    "\n",
    "print(\"‚úÖ Data Schemas Defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407e0d5",
   "metadata": {
    "papermill": {
     "duration": 0.009154,
     "end_time": "2025-11-30T08:12:01.510392",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.501238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 5: Active Memory Manager\n",
    "* **Purpose:** Manages the long-term memory of the system.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * `consolidate_memory`: Takes a new insight, checks if it already exists in the database, and saves it if it's new. This mimics how humans learn.\n",
    "\n",
    "    * `get_relevant_memory`: Retrieves the most recent facts from the database to provide context to the agents before they start a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97c742a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.530488Z",
     "iopub.status.busy": "2025-11-30T08:12:01.530210Z",
     "iopub.status.idle": "2025-11-30T08:12:01.538041Z",
     "shell.execute_reply": "2025-11-30T08:12:01.536407Z"
    },
    "papermill": {
     "duration": 0.019737,
     "end_time": "2025-11-30T08:12:01.539586",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.519849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory Manager Online.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: ACTIVE MEMORY MANAGER ---\n",
    "\n",
    "model_config = Gemini(model=\"gemini-2.5-flash-lite\")\n",
    "\n",
    "def consolidate_memory(new_insight: str):\n",
    "    \"\"\"\n",
    "    Uses an LLM to merge new facts with existing database memories.\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        # 1. Fetch existing memories\n",
    "        existing = conn.execute(\"SELECT fact FROM memory_bank\").fetchall()\n",
    "        existing_text = \"\\n\".join([r[0] for r in existing])\n",
    "        \n",
    "        # 2. LLM Decision: Update or Insert?\n",
    "        # (Simulated logic for brevity in demo, normally a separate LLM call)\n",
    "        if new_insight not in existing_text:\n",
    "            conn.execute(\n",
    "                \"INSERT INTO memory_bank (fact, confidence, last_updated) VALUES (?, ?, ?)\",\n",
    "                (new_insight, 1.0, datetime.now().isoformat())\n",
    "            )\n",
    "            print(f\"üß† [MEMORY] Learned new fact: {new_insight}\")\n",
    "        else:\n",
    "            print(f\"üß† [MEMORY] Fact already known, reinforced.\")\n",
    "\n",
    "def get_relevant_memory() -> str:\n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        facts = conn.execute(\"SELECT fact FROM memory_bank ORDER BY last_updated DESC LIMIT 5\").fetchall()\n",
    "    return \"\\n\".join([f\"- {f[0]}\" for f in facts]) if facts else \"No prior memory.\"\n",
    "\n",
    "print(\"‚úÖ Memory Manager Online.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba95c7",
   "metadata": {
    "papermill": {
     "duration": 0.008854,
     "end_time": "2025-11-30T08:12:01.557568",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.548714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 6: Secure Toolkit\n",
    "* **Purpose:** Defines the actual functions the agents can use to interact with the world.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * `run_sql_analytics`: Allows agents to run SQL queries on the database. It includes a security check (`SecurityGuard`) and logs the action to the `traces` table (Observability).\n",
    "\n",
    "    * `save_chart_config`: Validates chart data against the `DashboardSpec` schema to ensure it's correct before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a848b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.577210Z",
     "iopub.status.busy": "2025-11-30T08:12:01.576929Z",
     "iopub.status.idle": "2025-11-30T08:12:01.587728Z",
     "shell.execute_reply": "2025-11-30T08:12:01.585567Z"
    },
    "papermill": {
     "duration": 0.022474,
     "end_time": "2025-11-30T08:12:01.589447",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.566973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Secure Tools Configured.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 6: SECURE TOOLKIT ---\n",
    "\n",
    "def run_sql_analytics(query: str) -> str:\n",
    "    \"\"\"Executes READ-ONLY SQL on the sales db.\"\"\"\n",
    "    \n",
    "    # 1. Security Check\n",
    "    if not SecurityGuard.scan_input(query):\n",
    "        return \"ERROR: Query blocked by Security Guard.\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        with sqlite3.connect(DB_NAME) as conn:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            result = df.to_markdown()\n",
    "            \n",
    "        # 2. Observability Trace\n",
    "        latency = (time.time() - start_time) * 1000\n",
    "        with sqlite3.connect(DB_NAME) as conn:\n",
    "            conn.execute(\n",
    "                \"INSERT INTO traces VALUES (?,?,?,?,?,?,?)\",\n",
    "                (str(uuid.uuid4()), datetime.now().isoformat(), \"DataTool\", \"SQL_EXEC\", query, \"Success\", latency)\n",
    "            )\n",
    "            \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"SQL Error: {e}\"\n",
    "\n",
    "def save_chart_config(config_json: str) -> str:\n",
    "    \"\"\"Saves a dashboard configuration.\"\"\"\n",
    "    # In a real app, this would generate the image. \n",
    "    # For the demo, we validate the schema.\n",
    "    try:\n",
    "        # Validate against Pydantic schema\n",
    "        data = json.loads(config_json)\n",
    "        spec = DashboardSpec(**data) \n",
    "        return f\"‚úÖ Dashboard '{spec.title}' configuration valid and saved.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Invalid Config Schema: {e}\"\n",
    "\n",
    "# ADK Wrappers\n",
    "sql_tool = FunctionTool(run_sql_analytics)\n",
    "chart_tool = FunctionTool(save_chart_config)\n",
    "\n",
    "print(\"‚úÖ Secure Tools Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b58bed",
   "metadata": {
    "papermill": {
     "duration": 0.0084,
     "end_time": "2025-11-30T08:12:01.606981",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.598581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 7: Data Engineer Agent\n",
    "* **Purpose:** Defines the first specialist agent.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Creates an `LlmAgent` named `SeniorDataEngineer`.\n",
    "\n",
    "    * **Instruction:** Tells the agent its role is to write and execute SQL queries to retrieve raw data.\n",
    "\n",
    "    * Tool: Gives it access to `sql_tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984cca6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.627936Z",
     "iopub.status.busy": "2025-11-30T08:12:01.626401Z",
     "iopub.status.idle": "2025-11-30T08:12:01.634382Z",
     "shell.execute_reply": "2025-11-30T08:12:01.632595Z"
    },
    "papermill": {
     "duration": 0.020282,
     "end_time": "2025-11-30T08:12:01.636271",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.615989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Engineer Ready.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 7: DATA ENGINEER AGENT ---\n",
    "\n",
    "engineer = LlmAgent(\n",
    "    name=\"SeniorDataEngineer\",\n",
    "    model=model_config,\n",
    "    tools=[sql_tool],\n",
    "    instruction=f\"\"\"\n",
    "    Role: Senior Data Engineer.\n",
    "    Context: Access to 'sales_data' table (cols: region, product, amount, customer_sentiment).\n",
    "    Task: \n",
    "    1. Write SQL to answer the user's analytical question.\n",
    "    2. EXECUTE the SQL using `run_sql_analytics`.\n",
    "    3. Return the raw data table.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"‚úÖ Data Engineer Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4da077",
   "metadata": {
    "papermill": {
     "duration": 0.009998,
     "end_time": "2025-11-30T08:12:01.656657",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.646659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 8: Strategic Analyst Agent\n",
    "* **Purpose:** Defines the second specialist agent.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Creates an `LlmAgent` named `StrategicAnalyst`.\n",
    "\n",
    "    * **Instruction:** Tells the agent to analyze the data provided by the engineer and compare it against the \"Corporate Memory\" context. It does pure reasoning (no extra tools needed here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a7d111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.679270Z",
     "iopub.status.busy": "2025-11-30T08:12:01.678957Z",
     "iopub.status.idle": "2025-11-30T08:12:01.685004Z",
     "shell.execute_reply": "2025-11-30T08:12:01.683635Z"
    },
    "papermill": {
     "duration": 0.020583,
     "end_time": "2025-11-30T08:12:01.686850",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.666267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Strategic Analyst Ready.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 8: STRATEGIC ANALYST AGENT ---\n",
    "\n",
    "analyst = LlmAgent(\n",
    "    name=\"StrategicAnalyst\",\n",
    "    model=model_config,\n",
    "    # No tools needed, pure reasoning on input data\n",
    "    instruction=\"\"\"\n",
    "    Role: Lead Business Analyst.\n",
    "    Task:\n",
    "    1. Analyze the provided data table.\n",
    "    2. Identify trends in Revenue and Sentiment.\n",
    "    3. IMPORTANT: Compare these findings against the \"Corporate Memory\" context provided.\n",
    "    4. Output a strategic summary.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"‚úÖ Strategic Analyst Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8005a1c",
   "metadata": {
    "papermill": {
     "duration": 0.009267,
     "end_time": "2025-11-30T08:12:01.706122",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.696855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 9: Visualization Agent\n",
    "* **Purpose:** Defines the third specialist agent.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "  * Creates an `LlmAgent` named `VizExpert`.\n",
    "\n",
    "  * **Instruction:** Tells the agent to take the analysis and create a chart configuration JSON.\n",
    "\n",
    "* **Tool:** Gives it access to `chart_tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de34872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.726907Z",
     "iopub.status.busy": "2025-11-30T08:12:01.726549Z",
     "iopub.status.idle": "2025-11-30T08:12:01.733063Z",
     "shell.execute_reply": "2025-11-30T08:12:01.731233Z"
    },
    "papermill": {
     "duration": 0.019856,
     "end_time": "2025-11-30T08:12:01.735582",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.715726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualization Agent Ready.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 9: VISUALIZATION AGENT ---\n",
    "\n",
    "viz_agent = LlmAgent(\n",
    "    name=\"VizExpert\",\n",
    "    model=model_config,\n",
    "    tools=[chart_tool],\n",
    "    instruction=\"\"\"\n",
    "    Role: Dashboard Developer.\n",
    "    Task:\n",
    "    1. Create a JSON configuration for a chart based on the analysis.\n",
    "    2. MUST adhere to schema: {title, chart_type, x_axis, y_axis, data_points}.\n",
    "    3. Call `save_chart_config` with this JSON.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"‚úÖ Visualization Agent Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f113c98",
   "metadata": {
    "papermill": {
     "duration": 0.009553,
     "end_time": "2025-11-30T08:12:01.756190",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.746637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 10: Workflow Orchestration\n",
    "\n",
    "* **Purpose:** Connects the agents into a team.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Creates a `SequentialAgent` named `InsightSwarm_Enterprise`.\n",
    "\n",
    "    * **Sub-agents:** Lists `[engineer, analyst, viz_agent]`, meaning they will run one after another in that specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3372e10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.776090Z",
     "iopub.status.busy": "2025-11-30T08:12:01.775773Z",
     "iopub.status.idle": "2025-11-30T08:12:01.781852Z",
     "shell.execute_reply": "2025-11-30T08:12:01.780637Z"
    },
    "papermill": {
     "duration": 0.017909,
     "end_time": "2025-11-30T08:12:01.783417",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.765508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Orchestrator Configured.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 10: WORKFLOW ORCHESTRATION ---\n",
    "\n",
    "swarm = SequentialAgent(\n",
    "    name=\"InsightSwarm_Enterprise\",\n",
    "    description=\"Secure, Memory-Aware Analytics Pipeline\",\n",
    "    sub_agents=[engineer, analyst, viz_agent]\n",
    ")\n",
    "print(\"‚úÖ Orchestrator Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20afb9",
   "metadata": {
    "papermill": {
     "duration": 0.008402,
     "end_time": "2025-11-30T08:12:01.801498",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.793096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 11: Runtime Setup\n",
    "\n",
    "* **Purpose:** Initializes the application runtime.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Wraps the agent swarm in an `App` object with `ResumabilityConfig`, which allows the system to pause and resume (important for production reliability).\n",
    "\n",
    "    * Sets up the `Runner`, which executes the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c335f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.824227Z",
     "iopub.status.busy": "2025-11-30T08:12:01.823759Z",
     "iopub.status.idle": "2025-11-30T08:12:01.834495Z",
     "shell.execute_reply": "2025-11-30T08:12:01.832774Z"
    },
    "papermill": {
     "duration": 0.024573,
     "end_time": "2025-11-30T08:12:01.836289",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.811716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runtime Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/4276045501.py:6: UserWarning: [EXPERIMENTAL] ResumabilityConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  resumability_config=ResumabilityConfig(is_resumable=True)\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 11: RUNTIME SETUP ---\n",
    "\n",
    "app = App(\n",
    "    name=\"InsightSwarmApp\",\n",
    "    root_agent=swarm,\n",
    "    resumability_config=ResumabilityConfig(is_resumable=True)\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(app=app, session_service=session_service)\n",
    "\n",
    "print(\"‚úÖ Runtime Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c637f6b",
   "metadata": {
    "papermill": {
     "duration": 0.010132,
     "end_time": "2025-11-30T08:12:01.857800",
     "exception": false,
     "start_time": "2025-11-30T08:12:01.847668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 12: Execution (Fixed)\n",
    "\n",
    "* **Purpose:** Runs the first full test of the system.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * **Context Retrieval:** Calls `get_relevant_memory()` to load past knowledge.\n",
    "    \n",
    "    * **Session Creation:** Explicitly registers a new session ID.\n",
    "    \n",
    "    * **Execution Loop:** Runs the agent swarm with a user query.\n",
    "    \n",
    "    * **Output:** Prints the conversation step-by-step as the agents work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "510c2f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:12:01.878055Z",
     "iopub.status.busy": "2025-11-30T08:12:01.877675Z",
     "iopub.status.idle": "2025-11-30T08:12:01.998633Z",
     "shell.execute_reply": "2025-11-30T08:12:01.996978Z"
    },
    "papermill": {
     "duration": 0.134741,
     "end_time": "2025-11-30T08:12:02.001388",
     "exception": true,
     "start_time": "2025-11-30T08:12:01.866647",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Loaded Context:\n",
      "No prior memory.\n",
      "\n",
      "‚úÖ Session Created: run_1764490321\n",
      "üöÄ Starting Pipeline Run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/google/adk/agents/sequential_agent.py:72: UserWarning: [EXPERIMENTAL] SequentialAgentState: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  agent_state = SequentialAgentState(current_sub_agent=sub_agent.name)\n",
      "/usr/local/lib/python3.11/dist-packages/google/adk/utils/feature_decorator.py:87: UserWarning: [EXPERIMENTAL] BaseAgentState: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return orig_init(self, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/3051096414.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 4. Run (Using the created session_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m async for event in runner.run_async(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0msession_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvocation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\u001b[0m in \u001b[0;36m_run_with_trace\u001b[0;34m(new_message, invocation_id)\u001b[0m\n\u001b[1;32m    425\u001b[0m             )\n\u001b[1;32m    426\u001b[0m         ) as agen:\n\u001b[0;32m--> 427\u001b[0;31m           \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Run compaction after all events are yielded from the agent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\u001b[0m in \u001b[0;36m_exec_with_plugin\u001b[0;34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0;31m# Step 2: Otherwise continue with normal execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_append_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_live_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInvocationContext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAsyncGenerator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m           \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m               \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, parent_context)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_async_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/sequential_agent.py\u001b[0m in \u001b[0;36m_run_async_impl\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_pause_invocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, parent_context)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_async_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\u001b[0m in \u001b[0;36m_run_async_impl\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mshould_pause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__maybe_save_output_to_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mlast_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_step_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m           \u001b[0mlast_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_run_one_step_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m     ) as agen:\n\u001b[0;32m--> 433\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mllm_response\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Postprocess after calling the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         async with Aclosing(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_call_llm_async\u001b[0;34m(self, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_call_llm_with_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_call_llm_with_tracing\u001b[0;34m()\u001b[0m\n\u001b[1;32m    786\u001b[0m               )\n\u001b[1;32m    787\u001b[0m           ) as agen:\n\u001b[0;32m--> 788\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mllm_response\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m               trace_call_llm(\n\u001b[1;32m    790\u001b[0m                   \u001b[0minvocation_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_run_and_handle_error\u001b[0;34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0merror_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmodel_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__get_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvocation_context\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInvocationContext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBaseLlm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_run_and_handle_error\u001b[0;34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_generator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m           \u001b[0;32myield\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\u001b[0m in \u001b[0;36mgenerate_content_async\u001b[0;34m(self, llm_request, stream)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mLlmResponse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_append_user_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\u001b[0m in \u001b[0;36m_preprocess_request\u001b[0;34m(self, llm_request)\u001b[0m\n\u001b[1;32m    305\u001b[0m   \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_request\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLlmRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoogleLLMVariant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGEMINI_API\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;31m# Using API key from Google AI Studio to call model doesn't support labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mllm_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/functools.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\u001b[0m in \u001b[0;36m_api_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m     return (\n\u001b[1;32m    213\u001b[0m         \u001b[0mGoogleLLMVariant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERTEX_AI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertexai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0mGoogleLLMVariant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGEMINI_API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     )\n",
      "\u001b[0;32m/usr/lib/python3.11/functools.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\u001b[0m in \u001b[0;36mapi_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mapi\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \"\"\"\n\u001b[0;32m--> 203\u001b[0;31m     return Client(\n\u001b[0m\u001b[1;32m    204\u001b[0m         http_options=types.HttpOptions(\n\u001b[1;32m    205\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/sitecustomize.py\u001b[0m in \u001b[0;36minit_wrapper\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Thus, if the client constructor contains any params other than api_key, we don't set up forwarding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         default_metadata = {\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mhttp_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHttpOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     self._api_client = self._get_api_client(\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mvertexai\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertexai\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/client.py\u001b[0m in \u001b[0;36m_get_api_client\u001b[0;34m(vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[0m\n\u001b[1;32m    309\u001b[0m       )\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     return BaseApiClient(\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mvertexai\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertexai\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vertexai, api_key, credentials, project, location, http_options)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Implicit initialization or missing arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    677\u001b[0m             \u001b[0;34m'Missing key inputs argument! To use the Google AI API,'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;34m' provide (`api_key`) arguments. To use the Google Cloud API,'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments."
     ]
    }
   ],
   "source": [
    "# --- CELL 12: EXECUTION (FIXED) ---\n",
    "import time\n",
    "\n",
    "# 1. Retrieve Context\n",
    "memory_context = get_relevant_memory()\n",
    "print(f\"üß† Loaded Context:\\n{memory_context}\\n\")\n",
    "\n",
    "# 2. User Query\n",
    "query = \"Analyze sales performance and sentiment by Region. Compare with our known history.\"\n",
    "\n",
    "# 3. Construct Prompt\n",
    "final_prompt = f\"\"\"\n",
    "CONTEXT:\n",
    "{memory_context}\n",
    "\n",
    "USER REQUEST:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# --- FIX: Create Session ID and Register it First ---\n",
    "current_time = int(time.time())\n",
    "session_id = f\"run_{current_time}\"\n",
    "user_id = \"admin\"\n",
    "\n",
    "# Create the session in the service explicitly\n",
    "await session_service.create_session(\n",
    "    app_name=app.name,\n",
    "    user_id=user_id,\n",
    "    session_id=session_id\n",
    ")\n",
    "print(f\"‚úÖ Session Created: {session_id}\")\n",
    "\n",
    "print(f\"üöÄ Starting Pipeline Run...\")\n",
    "\n",
    "# 4. Run (Using the created session_id)\n",
    "async for event in runner.run_async(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    new_message=types.Content(role=\"user\", parts=[types.Part(text=final_prompt)])\n",
    "):\n",
    "    if event.content and event.content.parts:\n",
    "        for part in event.content.parts:\n",
    "            if part.text:\n",
    "                print(f\"\\nü§ñ [{event.author}]: {part.text[:100]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c0395",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 13: LLM-as-a-Judge\n",
    "\n",
    "* **Purpose:** Automatically evaluates the quality of the run.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Reads the traces `table` to see what happened.\n",
    "    \n",
    "    * Checks criteria: Did it run SQL? Was it fast?\n",
    "    \n",
    "    * Calculates a score (0-100) and saves it to the `eval_scores` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d8375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:10:51.802774Z",
     "iopub.status.busy": "2025-11-29T11:10:51.802370Z",
     "iopub.status.idle": "2025-11-29T11:10:51.825006Z",
     "shell.execute_reply": "2025-11-29T11:10:51.823650Z",
     "shell.execute_reply.started": "2025-11-29T11:10:51.802746Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 13: LLM-AS-A-JUDGE ---\n",
    "\n",
    "def run_evaluation():\n",
    "    print(\"\\n‚öñÔ∏è [JUDGE] Starting Post-Run Evaluation...\")\n",
    "    \n",
    "    # 1. Fetch the Trace\n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        traces = conn.execute(\"SELECT * FROM traces\").fetchall()\n",
    "    \n",
    "    # 2. Evaluation Logic (Simulated LLM Call)\n",
    "    # In prod, you would send the trace to Gemini Pro for scoring\n",
    "    has_sql = any(\"SQL_EXEC\" in t[3] for t in traces)\n",
    "    latency_ok = all(t[6] < 5000 for t in traces) # < 5s latency\n",
    "    \n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    if has_sql: \n",
    "        score += 50\n",
    "        reasons.append(\"‚úÖ Valid SQL Execution detected.\")\n",
    "    else:\n",
    "        reasons.append(\"‚ùå No SQL Execution found.\")\n",
    "        \n",
    "    if latency_ok:\n",
    "        score += 50\n",
    "        reasons.append(\"‚úÖ Latency within SLA limits.\")\n",
    "        \n",
    "    # 3. Save Score\n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        conn.execute(\n",
    "            \"INSERT INTO eval_scores VALUES (?,?,?,?)\",\n",
    "            (\"current_run\", \"Quality\", score, \"; \".join(reasons))\n",
    "        )\n",
    "    \n",
    "    print(f\"üèÜ Final Quality Score: {score}/100\")\n",
    "    for r in reasons: print(f\"   {r}\")\n",
    "\n",
    "run_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f957cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 14: Memory Consolidation\n",
    "\n",
    "* **Purpose:** Teaches the system something new based on the run.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Takes a new fact (\"West region has highest revenue...\") and calls `consolidate_memory` to save it to the database for future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d3060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:10:59.308221Z",
     "iopub.status.busy": "2025-11-29T11:10:59.307922Z",
     "iopub.status.idle": "2025-11-29T11:10:59.329731Z",
     "shell.execute_reply": "2025-11-29T11:10:59.328369Z",
     "shell.execute_reply.started": "2025-11-29T11:10:59.308201Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 14: MEMORY CONSOLIDATION ---\n",
    "\n",
    "print(\"\\nüß† [SYSTEM] Consolidating Session into Memory Bank...\")\n",
    "\n",
    "# Simulate extracting a key fact from the recent run\n",
    "new_fact = \"West region has highest revenue but lowest sentiment.\"\n",
    "\n",
    "consolidate_memory(new_fact)\n",
    "\n",
    "# Verify\n",
    "with sqlite3.connect(DB_NAME) as conn:\n",
    "    mems = conn.execute(\"SELECT * FROM memory_bank\").fetchall()\n",
    "    print(f\"üìö Current Knowledge Base ({len(mems)} facts):\")\n",
    "    for m in mems:\n",
    "        print(f\"   - {m[1]} (Conf: {m[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d8fca",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 15: Visualization Engine\n",
    "\n",
    "* **Purpose:** Adds the capability to actually generate image files.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Installs plotting libraries (`matplotlib`, `seaborn`).\n",
    "    \n",
    "    * `render_plot`: A function that takes Python code as input, executes it, and checks if a `dashboard.png` file was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4c390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:11:10.614766Z",
     "iopub.status.busy": "2025-11-29T11:11:10.614387Z",
     "iopub.status.idle": "2025-11-29T11:11:15.568302Z",
     "shell.execute_reply": "2025-11-29T11:11:15.566944Z",
     "shell.execute_reply.started": "2025-11-29T11:11:10.614741Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 15: VISUALIZATION ENGINE ---\n",
    "!pip install -q matplotlib seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def render_plot(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes plotting code and saves 'dashboard.png'.\n",
    "    Injects necessary libraries automatically.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pre-load context for the plot\n",
    "        exec_globals = globals().copy()\n",
    "        exec_globals['plt'] = plt\n",
    "        exec_globals['sns'] = sns\n",
    "        exec_globals['pd'] = pd\n",
    "        \n",
    "        # Safe execution wrapper\n",
    "        exec(code, exec_globals)\n",
    "        \n",
    "        if os.path.exists('dashboard.png'):\n",
    "            return \"‚úÖ SUCCESS: Chart generated and saved to 'dashboard.png'.\"\n",
    "        else:\n",
    "            return \"‚ùå ERROR: Code ran, but 'dashboard.png' was not found. Did you call plt.savefig()?\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå PLOTTING ERROR: {e}\"\n",
    "\n",
    "plot_tool = FunctionTool(render_plot)\n",
    "print(\"‚úÖ Visualization Engine Online (Matplotlib/Seaborn).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f42d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 16: Critic Agent\n",
    "\n",
    "* **Purpose:** Adds a quality control layer.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Creates an agent `DesignCritic` whose job is to review code and say \"APPROVED\" or give feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6be98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:11:23.251990Z",
     "iopub.status.busy": "2025-11-29T11:11:23.251249Z",
     "iopub.status.idle": "2025-11-29T11:11:23.258980Z",
     "shell.execute_reply": "2025-11-29T11:11:23.257395Z",
     "shell.execute_reply.started": "2025-11-29T11:11:23.251954Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 16: CRITIC AGENT (QUALITY GATE) ---\n",
    "\n",
    "critic = LlmAgent(\n",
    "    name=\"DesignCritic\",\n",
    "    model=model_config,\n",
    "    instruction=\"\"\"\n",
    "    Role: Senior Dashboard Reviewer.\n",
    "    Task: \n",
    "    1. Review the Python code generated by the VizExpert.\n",
    "    2. CHECK: Does it handle empty data? Does it use the corporate color (#1f77b4)?\n",
    "    3. CHECK: Is the title clear?\n",
    "    \n",
    "    Output:\n",
    "    - If perfect, respond EXACTLY: \"APPROVED\".\n",
    "    - If flawed, provide specific feedback on how to fix the code.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"‚úÖ Design Critic Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282fae5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 17: Upgraded Viz Agent\n",
    "\n",
    "* **Purpose:** Improves the visualization agent to use the new plotting engine.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Creates `VizExpert_V2` which uses `plot_tool` (real plotting) instead of the old JSON tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97651274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:11:31.172604Z",
     "iopub.status.busy": "2025-11-29T11:11:31.172207Z",
     "iopub.status.idle": "2025-11-29T11:11:31.178570Z",
     "shell.execute_reply": "2025-11-29T11:11:31.177472Z",
     "shell.execute_reply.started": "2025-11-29T11:11:31.172577Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 17: UPGRADED VIZ AGENT ---\n",
    "\n",
    "viz_agent_v2 = LlmAgent(\n",
    "    name=\"VizExpert_V2\",\n",
    "    model=model_config,\n",
    "    tools=[plot_tool], # Now has the real plotting tool\n",
    "    instruction=\"\"\"\n",
    "    Role: Data Visualization Engineer.\n",
    "    Task:\n",
    "    1. Read the 'sales_data' table using Pandas (assume DB connection exists).\n",
    "    2. Generate a Bar Chart: Sales by Region.\n",
    "    3. REQUIREMENT: Use hex color '#1f77b4'. Title: 'Q4 Regional Performance'.\n",
    "    4. Save plot as 'dashboard.png'.\n",
    "    5. Use `render_plot` to execute.\n",
    "    6. If you receive feedback from the Critic, adjust code and retry.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"‚úÖ VizExpert V2 (Active Plotting) Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd19fc9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 18: Refinement Loop\n",
    "\n",
    "* **Purpose:** Creates a self-correcting workflow.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    Uses `LoopAgent` to cycle between `VizExpert_V2` and `critic` until the critic approves the work (or max 3 tries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289c700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:11:39.707040Z",
     "iopub.status.busy": "2025-11-29T11:11:39.706730Z",
     "iopub.status.idle": "2025-11-29T11:11:39.713692Z",
     "shell.execute_reply": "2025-11-29T11:11:39.712770Z",
     "shell.execute_reply.started": "2025-11-29T11:11:39.707019Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 18: REFINEMENT LOOP ---\n",
    "\n",
    "from google.adk.agents import LoopAgent\n",
    "\n",
    "design_loop = LoopAgent(\n",
    "    name=\"VisualizationLoop\",\n",
    "    description=\"Iterates on charts until they meet quality standards.\",\n",
    "    sub_agents=[viz_agent_v2, critic],\n",
    "    max_iterations=3 # Safety limit\n",
    ")\n",
    "print(\"‚úÖ Refinement Loop Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6521d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 19: V2 Orchestrator\n",
    "\n",
    "* **Purpose:** Rebuilds the team with the new V2 agents.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Re-instantiates Engineer and Analyst agents (to avoid \"parent agent\" conflicts).\n",
    "    \n",
    "    * Creates `swarm_v2` which uses the new `design_loop` instead of a single viz agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e4ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:11:48.428551Z",
     "iopub.status.busy": "2025-11-29T11:11:48.428151Z",
     "iopub.status.idle": "2025-11-29T11:11:48.438529Z",
     "shell.execute_reply": "2025-11-29T11:11:48.437605Z",
     "shell.execute_reply.started": "2025-11-29T11:11:48.428523Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 19: V2 ORCHESTRATOR (FIXED) ---\n",
    "\n",
    "# 1. Re-instantiate Agents (Fixes \"Already has a parent\" error)\n",
    "# We must create fresh instances because the old ones are locked to the V1 Swarm.\n",
    "engineer_v2 = LlmAgent(\n",
    "    name=\"SeniorDataEngineer_V2\",\n",
    "    model=model_config,\n",
    "    tools=[sql_tool], # Reusing the secure SQL tool\n",
    "    instruction=\"\"\"\n",
    "    Role: Senior Data Engineer.\n",
    "    Context: Access to 'sales_data' table (cols: region, product, amount, customer_sentiment).\n",
    "    Task: \n",
    "    1. Write SQL to answer the user's analytical question.\n",
    "    2. EXECUTE the SQL using `run_sql_analytics`.\n",
    "    3. Return the raw data table.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "analyst_v2 = LlmAgent(\n",
    "    name=\"StrategicAnalyst_V2\",\n",
    "    model=model_config,\n",
    "    instruction=\"\"\"\n",
    "    Role: Lead Business Analyst.\n",
    "    Task:\n",
    "    1. Analyze the provided data table.\n",
    "    2. Identify trends in Revenue and Sentiment.\n",
    "    3. IMPORTANT: Compare these findings against the \"Corporate Memory\" context provided.\n",
    "    4. Output a strategic summary.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 2. Define V2 Swarm\n",
    "# We use the new V2 agents + the Design Loop we created in Cell 18\n",
    "swarm_v2 = SequentialAgent(\n",
    "    name=\"InsightSwarm_V2\",\n",
    "    description=\"Enterprise Pipeline with Quality Control\",\n",
    "    sub_agents=[engineer_v2, analyst_v2, design_loop] \n",
    ")\n",
    "\n",
    "# 3. Setup V2 App\n",
    "app_v2 = App(\n",
    "    name=\"InsightSwarmApp_V2\",\n",
    "    root_agent=swarm_v2,\n",
    "    resumability_config=ResumabilityConfig(is_resumable=True)\n",
    ")\n",
    "\n",
    "# 4. Setup V2 Runner\n",
    "runner_v2 = Runner(app=app_v2, session_service=InMemorySessionService())\n",
    "\n",
    "print(\"‚úÖ V2 Architecture Live (Engineer V2 -> Analyst V2 -> Design Loop).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327329fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 20: Execution (V2)\n",
    "\n",
    "* **Purpose:** Runs the upgraded, self-correcting pipeline.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Similar to Cell 12 but uses `runner_v2`.\n",
    "    \n",
    "    * Explicitly creates a session before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb2c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:14:02.891262Z",
     "iopub.status.busy": "2025-11-29T11:14:02.890250Z",
     "iopub.status.idle": "2025-11-29T11:14:12.698360Z",
     "shell.execute_reply": "2025-11-29T11:14:12.697378Z",
     "shell.execute_reply.started": "2025-11-29T11:14:02.891228Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 20: EXECUTION (FIXED) ---\n",
    "import time\n",
    "\n",
    "# 1. Define Session ID\n",
    "session_id_v2 = f\"run_v2_{int(time.time())}\"\n",
    "print(f\"üöÄ Starting V2 Pipeline (Session: {session_id_v2})...\")\n",
    "\n",
    "# --- FIX: Create Session Explicitly First ---\n",
    "# We access the session_service which is in runner_v2\n",
    "await runner_v2.session_service.create_session(\n",
    "    app_name=app_v2.name,\n",
    "    user_id=\"admin\",\n",
    "    session_id=session_id_v2\n",
    ")\n",
    "print(f\"‚úÖ Session Created: {session_id_v2}\")\n",
    "\n",
    "# 2. Re-using the context from before\n",
    "# Make sure memory_context is defined (from Cell 12)\n",
    "try:\n",
    "    memory_context\n",
    "except NameError:\n",
    "    memory_context = \"No prior memory context.\"\n",
    "\n",
    "prompt_v2 = f\"\"\"\n",
    "CONTEXT:\n",
    "{memory_context}\n",
    "\n",
    "TASK:\n",
    "Analyze Q4 Sales. Then, generate a high-quality, APPROVED dashboard image comparing Sales by Region.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Run\n",
    "async for event in runner_v2.run_async(\n",
    "    user_id=\"admin\",\n",
    "    session_id=session_id_v2,\n",
    "    new_message=types.Content(role=\"user\", parts=[types.Part(text=prompt_v2)])\n",
    "):\n",
    "    if event.content and event.content.parts:\n",
    "        for part in event.content.parts:\n",
    "            if part.text:\n",
    "                print(f\"\\nü§ñ [{event.author}]: {part.text[:100]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ V2 Run Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a73420",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 21: Visual Output\n",
    "\n",
    "* **Purpose:** Displays the result.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Checks for `dashboard.png` and displays it in the notebook if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e124443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:16:06.278295Z",
     "iopub.status.busy": "2025-11-29T11:16:06.277921Z",
     "iopub.status.idle": "2025-11-29T11:16:06.287918Z",
     "shell.execute_reply": "2025-11-29T11:16:06.286764Z",
     "shell.execute_reply.started": "2025-11-29T11:16:06.278271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 21: VISUAL OUTPUT (FIXED) ---\n",
    "import os\n",
    "from IPython.display import Image, display  # <--- Import is mandatory\n",
    "\n",
    "print(\"üìä Dashboard Output:\")\n",
    "\n",
    "if os.path.exists('dashboard.png'):\n",
    "    display(Image(filename='dashboard.png'))\n",
    "else:\n",
    "    print(\"‚ùå No dashboard generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf2a32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 22: Entity Extraction\n",
    "\n",
    "* **Purpose:** Demonstrates deeper memory capabilities.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Simulates extracting specific entities (like \"North Region\") from text, which would be useful for building a Knowledge Graph in a real enterprise system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72fe83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:16:51.644642Z",
     "iopub.status.busy": "2025-11-29T11:16:51.644284Z",
     "iopub.status.idle": "2025-11-29T11:16:51.652168Z",
     "shell.execute_reply": "2025-11-29T11:16:51.651011Z",
     "shell.execute_reply.started": "2025-11-29T11:16:51.644618Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 22: ENTITY EXTRACTION ---\n",
    "\n",
    "def extract_entities(text: str):\n",
    "    \"\"\"Simulates extracting structured entities for the Knowledge Graph.\"\"\"\n",
    "    # In prod, use an LLM to output JSON\n",
    "    print(\"\\nüß† [MEMORY] Deep Extraction running...\")\n",
    "    \n",
    "    regions = [\"North\", \"South\", \"East\", \"West\"]\n",
    "    found = [r for r in regions if r in text]\n",
    "    \n",
    "    for f in found:\n",
    "        print(f\"   ‚Ü≥ Identified Entity: Region='{f}' (Active Context)\")\n",
    "        # Here you would insert into a Graph DB node\n",
    "\n",
    "# Run on the analyst's last output\n",
    "# (Simulated access to last message)\n",
    "extract_entities(\"Analysis shows West and North regions are outperforming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd8e50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 23: Compliance Audit\n",
    "\n",
    "* **Purpose:** Simulates an automated compliance check.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Verifies that the required artifact (`dashboard.png`) was actually created and meets standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d0b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:17:05.472462Z",
     "iopub.status.busy": "2025-11-29T11:17:05.472094Z",
     "iopub.status.idle": "2025-11-29T11:17:05.479185Z",
     "shell.execute_reply": "2025-11-29T11:17:05.477842Z",
     "shell.execute_reply.started": "2025-11-29T11:17:05.472436Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 23: COMPLIANCE AUDIT ---\n",
    "\n",
    "def audit_artifacts():\n",
    "    print(\"\\nüõ°Ô∏è [AUDIT] Verifying Brand Compliance...\")\n",
    "    # In reality, we'd inspect the code or image pixels\n",
    "    # Here we simulate a pass if the file exists\n",
    "    if os.path.exists('dashboard.png'):\n",
    "        print(\"   ‚úÖ Artifact 'dashboard.png' exists.\")\n",
    "        print(\"   ‚úÖ Brand Color Check: PASSED (Verified by Critic Agent)\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Compliance Failure: Missing Artifact\")\n",
    "\n",
    "audit_artifacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97a83b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 24: ROI Calculation\n",
    "\n",
    "* **Purpose:** Shows the business value.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Calculates time saved vs. human effort to demonstrate \"Return on Investment\" (ROI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf230f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:17:20.308469Z",
     "iopub.status.busy": "2025-11-29T11:17:20.308075Z",
     "iopub.status.idle": "2025-11-29T11:17:20.315945Z",
     "shell.execute_reply": "2025-11-29T11:17:20.314489Z",
     "shell.execute_reply.started": "2025-11-29T11:17:20.308441Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 24: ROI CALCULATION ---\n",
    "\n",
    "def calculate_roi():\n",
    "    # Mock data based on typical enterprise stats\n",
    "    human_time_min = 45 # Time to pull SQL + make chart in Excel\n",
    "    agent_time_min = 1.5\n",
    "    \n",
    "    savings = human_time_min - agent_time_min\n",
    "    efficiency_gain = (human_time_min / agent_time_min) * 100\n",
    "    \n",
    "    print(\"\\nüí∞ [BUSINESS VALUE] Run Summary:\")\n",
    "    print(f\"   - Human Equivalent Time: {human_time_min} mins\")\n",
    "    print(f\"   - Agent Runtime: {agent_time_min} mins\")\n",
    "    print(f\"   - Efficiency Gain: {efficiency_gain:.0f}%\")\n",
    "    print(f\"   - Status: READY FOR PRODUCTION\")\n",
    "\n",
    "calculate_roi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b762ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 25: Deployment Config\n",
    "\n",
    "* **Purpose:** Generates a configuration file for deployment.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Writes a `agent_manifest.json` file that describes the system settings for a cloud deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad19f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:17:29.434979Z",
     "iopub.status.busy": "2025-11-29T11:17:29.434618Z",
     "iopub.status.idle": "2025-11-29T11:17:29.443057Z",
     "shell.execute_reply": "2025-11-29T11:17:29.441897Z",
     "shell.execute_reply.started": "2025-11-29T11:17:29.434955Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 25: DEPLOYMENT CONFIG ---\n",
    "\n",
    "manifest = {\n",
    "    \"agent_name\": \"InsightSwarm_V2\",\n",
    "    \"runtime\": \"Vertex AI Agent Engine\",\n",
    "    \"scaling\": {\n",
    "        \"min_instances\": 1,\n",
    "        \"max_instances\": 5\n",
    "    },\n",
    "    \"security\": {\n",
    "        \"guardrails\": \"enabled\",\n",
    "        \"vpc_peering\": \"required\"\n",
    "    },\n",
    "    \"integrations\": [\n",
    "        \"sqlite_db\", \"corporate_memory.txt\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"agent_manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Deployment Manifest generated: 'agent_manifest.json'\")\n",
    "print(\"üöÄ Ready for 'adk deploy'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a2ef2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 26: CI/CD Smoke Test\n",
    "* **Purpose:** Simulates a pre-deployment test.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Checks if the database exists, if tools are configured, etc.\n",
    "    \n",
    "    * Only returns `True` (Ready for deploy) if all checks pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae81a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:17.999339Z",
     "iopub.status.busy": "2025-11-29T11:31:17.998939Z",
     "iopub.status.idle": "2025-11-29T11:31:18.010020Z",
     "shell.execute_reply": "2025-11-29T11:31:18.008914Z",
     "shell.execute_reply.started": "2025-11-29T11:31:17.999312Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 26: CI/CD PIPELINE SIMULATION (DB VERSION) ---\n",
    "\n",
    "def run_smoke_tests():\n",
    "    print(\"üè≠ [CI/CD] Starting Pre-Deployment Smoke Tests...\")\n",
    "    \n",
    "    # 1. Define Helper to check DB Table\n",
    "    def check_memory_table():\n",
    "        try:\n",
    "            with sqlite3.connect(DB_NAME) as conn:\n",
    "                # Cek apakah tabel memory_bank ada\n",
    "                conn.execute(\"SELECT count(*) FROM memory_bank\")\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    # 2. Define Tests\n",
    "    tests = [\n",
    "        (\"Database File Exists\", lambda: os.path.exists(DB_NAME)),\n",
    "        (\"Memory Bank Table Accessible\", check_memory_table), # <--- FIX: Cek Tabel SQL, bukan File txt\n",
    "        (\"Tool Configuration\", lambda: len(swarm.sub_agents) > 0), # Cek sub-agents di orchestrator\n",
    "        (\"Security Guard Active\", lambda: SecurityGuard.scan_input(\"system prompt\") == False)\n",
    "    ]\n",
    "    \n",
    "    # 3. Run Tests\n",
    "    all_passed = True\n",
    "    for name, test_fn in tests:\n",
    "        try:\n",
    "            result = test_fn()\n",
    "            status = \"‚úÖ PASS\" if result else \"‚ùå FAIL\"\n",
    "            if not result: all_passed = False\n",
    "        except Exception as e:\n",
    "            status = f\"‚ùå ERROR ({e})\"\n",
    "            all_passed = False\n",
    "        print(f\"   - {name}: {status}\")\n",
    "        \n",
    "    if all_passed:\n",
    "        print(\"\\nüöÄ [CI/CD] All checks passed. Artifact ready for deployment.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nüõë [CI/CD] Checks failed. Deployment aborted.\")\n",
    "        return False\n",
    "\n",
    "# Run the pipeline\n",
    "is_deployable = run_smoke_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f137ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 27: Responsible AI Scanner\n",
    "\n",
    "* **Purpose:** Checks output for harmful content.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Scans text for toxic words or potential bias (e.g., \"lazy\"). This ensures the agent is safe to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb5a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:25.803160Z",
     "iopub.status.busy": "2025-11-29T11:31:25.802271Z",
     "iopub.status.idle": "2025-11-29T11:31:25.810131Z",
     "shell.execute_reply": "2025-11-29T11:31:25.808912Z",
     "shell.execute_reply.started": "2025-11-29T11:31:25.803127Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 27: RESPONSIBLE AI SCANNER ---\n",
    "\n",
    "def scan_for_rai_risks(text: str):\n",
    "    print(\"\\nüõ°Ô∏è [RAI] Scanning output for Fairness and Safety...\")\n",
    "    \n",
    "    # Simulated checks\n",
    "    risks = []\n",
    "    \n",
    "    # 1. Tone Check\n",
    "    if \"stupid\" in text.lower() or \"idiot\" in text.lower():\n",
    "        risks.append(\"Toxic Language detected\")\n",
    "        \n",
    "    # 2. Bias Proxy Check (Simple Keyword)\n",
    "    # In prod, use a classifier. Here, we check if one region is unfairly singled out without data.\n",
    "    if \"West region is lazy\" in text: \n",
    "        risks.append(\"Potential Regional Bias detected\")\n",
    "        \n",
    "    if not risks:\n",
    "        print(\"   ‚úÖ RAI Scan Clean. Output is safe.\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è RAI Risks Found: {risks}\")\n",
    "\n",
    "# Test on a hypothetical bad output\n",
    "scan_for_rai_risks(\"The sales team in the West is lazy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f48db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 28: User Feedback Loop\n",
    "\n",
    "* **Purpose:** Closes the loop with the user.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Simulates a user giving a rating (5 stars).\n",
    "    \n",
    "    * Saves this rating to the `eval_scores` table so we can track user satisfaction over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ba74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:26.791994Z",
     "iopub.status.busy": "2025-11-29T11:31:26.791668Z",
     "iopub.status.idle": "2025-11-29T11:31:26.809868Z",
     "shell.execute_reply": "2025-11-29T11:31:26.808719Z",
     "shell.execute_reply.started": "2025-11-29T11:31:26.791971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 28: USER FEEDBACK LOOP ---\n",
    "\n",
    "def submit_user_feedback(run_id: str, rating: int, comments: str):\n",
    "    \"\"\"\n",
    "    Captures user sentiment (1-5 stars) to train future iterations.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìù [FEEDBACK] Receiving user input for Run {run_id}...\")\n",
    "    \n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        conn.execute(\n",
    "            \"INSERT INTO eval_scores (run_id, criteria, score, reasoning) VALUES (?, ?, ?, ?)\",\n",
    "            (run_id, \"User_CSAT\", rating, comments)\n",
    "        )\n",
    "    \n",
    "    if rating < 3:\n",
    "        print(\"   ‚ö†Ô∏è Low score detected! Flagging for human review.\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Positive feedback logged.\")\n",
    "\n",
    "# Simulate a user reacting to the dashboard\n",
    "submit_user_feedback(session_id_v2, 5, \"Great dashboard, exactly what I needed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c683a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 29: A/B Experimentation\n",
    "\n",
    "* **Purpose:** Simulates testing different strategies.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    \n",
    "    * Compares two different prompt variations (\"Baseline\" vs \"Aggressive\").\n",
    "    \n",
    "    * Decides which one is better based on a simulated score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36f5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:28.021988Z",
     "iopub.status.busy": "2025-11-29T11:31:28.021616Z",
     "iopub.status.idle": "2025-11-29T11:31:28.028949Z",
     "shell.execute_reply": "2025-11-29T11:31:28.027731Z",
     "shell.execute_reply.started": "2025-11-29T11:31:28.021963Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 29: A/B EXPERIMENTATION ---\n",
    "\n",
    "print(\"\\nüß™ [EXPERIMENT] Running A/B Test on Strategic Analyst Prompts...\")\n",
    "\n",
    "# Variant A (Current)\n",
    "prompt_a = \"Summarize strategic findings.\"\n",
    "\n",
    "# Variant B (More Aggressive)\n",
    "prompt_b = \"Summarize strategic findings and propose 3 bold, high-risk actions.\"\n",
    "\n",
    "# Simulate scoring (In prod, this would use the Eval Scorecard)\n",
    "score_a = 85 # Baseline\n",
    "score_b = 92 # Variant\n",
    "\n",
    "print(f\"   - Variant A Score: {score_a}\")\n",
    "print(f\"   - Variant B Score: {score_b}\")\n",
    "\n",
    "if score_b > score_a:\n",
    "    print(\"   ‚úÖ Variant B is superior. Promoting to Production...\")\n",
    "    # In a real system, this would update the Agent's system prompt code\n",
    "else:\n",
    "    print(\"   ‚ùå Variant B failed. Rolling back to A.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c9b5e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 30: System Health Report\n",
    "\n",
    "* **Purpose:** A dashboard for IT/Admin.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Queries the database to count rows in sales data, traces, and memories.\n",
    "    \n",
    "    * Shows the average quality score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f09fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:29.030991Z",
     "iopub.status.busy": "2025-11-29T11:31:29.030644Z",
     "iopub.status.idle": "2025-11-29T11:31:29.039018Z",
     "shell.execute_reply": "2025-11-29T11:31:29.038032Z",
     "shell.execute_reply.started": "2025-11-29T11:31:29.030966Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 30: SYSTEM HEALTH REPORT ---\n",
    "\n",
    "def generate_system_report():\n",
    "    print(\"\\nüìä [SYSTEM STATUS] InsightSwarm Enterprise V3\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        # 1. Data Health\n",
    "        row_count = conn.execute(\"SELECT count(*) FROM sales_data\").fetchone()[0]\n",
    "        print(f\"1. Data Warehouse:  ‚úÖ Online ({row_count} records)\")\n",
    "        \n",
    "        # 2. Trace Health\n",
    "        trace_count = conn.execute(\"SELECT count(*) FROM traces\").fetchone()[0]\n",
    "        print(f\"2. Observability:   ‚úÖ Active ({trace_count} traces captured)\")\n",
    "        \n",
    "        # 3. Memory Health\n",
    "        mem_count = conn.execute(\"SELECT count(*) FROM memory_bank\").fetchone()[0]\n",
    "        print(f\"3. Memory Bank:     ‚úÖ Learning ({mem_count} facts consolidated)\")\n",
    "        \n",
    "        # 4. Quality Score\n",
    "        avg_score = conn.execute(\"SELECT AVG(score) FROM eval_scores\").fetchone()[0]\n",
    "        print(f\"4. Quality Score:   ‚≠ê {avg_score:.1f}/100\")\n",
    "\n",
    "generate_system_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832ae1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 31: Fixed Reporting\n",
    "\n",
    "* **Purpose:** Corrects the reporting logic from Cell 30.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Separates \"Technical Score\" (0-100) from \"User Score\" (0-5).\n",
    "    \n",
    "    * Normalizes them to a common scale and calculates a weighted final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5324b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:31:29.627270Z",
     "iopub.status.busy": "2025-11-29T11:31:29.626965Z",
     "iopub.status.idle": "2025-11-29T11:31:29.636188Z",
     "shell.execute_reply": "2025-11-29T11:31:29.635255Z",
     "shell.execute_reply.started": "2025-11-29T11:31:29.627232Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 31: FIXED REPORTING (NORMALIZATION) ---\n",
    "\n",
    "def generate_professional_report():\n",
    "    print(\"\\nüìä [EXECUTIVE DASHBOARD] InsightSwarm Performance\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        # 1. Retrieve Metrics separated by type\n",
    "        tech_scores = conn.execute(\n",
    "            \"SELECT score FROM eval_scores WHERE criteria = 'Quality'\"\n",
    "        ).fetchall()\n",
    "        \n",
    "        user_scores = conn.execute(\n",
    "            \"SELECT score FROM eval_scores WHERE criteria = 'User_CSAT'\"\n",
    "        ).fetchall()\n",
    "        \n",
    "        # 2. Calculate Averages (Safe handling for empty lists)\n",
    "        avg_tech = sum([s[0] for s in tech_scores]) / len(tech_scores) if tech_scores else 0\n",
    "        avg_user = sum([s[0] for s in user_scores]) / len(user_scores) if user_scores else 0\n",
    "        \n",
    "        # 3. Display Corrected Metrics\n",
    "        print(f\"1. System Health:     ‚úÖ Online\")\n",
    "        print(f\"2. Technical Quality: ‚öôÔ∏è  {avg_tech:.1f}/100 (Automated Judge)\")\n",
    "        print(f\"3. User Satisfaction: ‚≠ê {avg_user:.1f}/5.0 (Human Feedback)\")\n",
    "        \n",
    "        # 4. Normalized Overall Score (Convert 5-star to 100-point scale)\n",
    "        # 5 stars = 100, 4 stars = 80, etc.\n",
    "        normalized_user = avg_user * 20 \n",
    "        total_score = (avg_tech + normalized_user) / 2\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"üèÜ FINAL WEIGHTED SCORE: {total_score:.1f}/100\")\n",
    "\n",
    "generate_professional_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594340ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 32: FinOps Analytics\n",
    "\n",
    "* **Purpose:** Tracks cost efficiency.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Estimates token usage based on log length.\n",
    "    \n",
    "    * Calculates the cost of the session in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec7946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:34:10.913610Z",
     "iopub.status.busy": "2025-11-29T11:34:10.913220Z",
     "iopub.status.idle": "2025-11-29T11:34:10.923894Z",
     "shell.execute_reply": "2025-11-29T11:34:10.922784Z",
     "shell.execute_reply.started": "2025-11-29T11:34:10.913586Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 32: FIN-OPS ANALYTICS ---\n",
    "\n",
    "def generate_cost_report():\n",
    "    print(\"\\nüí∞ [FIN-OPS] Operational Cost Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Mock pricing for Gemini Flash-Lite (approximate)\n",
    "    COST_PER_1K_INPUT = 0.00001\n",
    "    COST_PER_1K_OUTPUT = 0.00002\n",
    "    \n",
    "    # In a real ADK run, we would parse the `usage_metadata` from the raw logs.\n",
    "    # Since our demo simulation didn't write raw usage logs to SQL, we will simulate \n",
    "    # the token counts based on the text length of traces we DO have.\n",
    "    \n",
    "    with sqlite3.connect(DB_NAME) as conn:\n",
    "        # Estimate tokens: ~4 chars per token\n",
    "        inputs = conn.execute(\"SELECT input FROM traces\").fetchall()\n",
    "        outputs = conn.execute(\"SELECT output FROM traces\").fetchall()\n",
    "    \n",
    "    total_input_chars = sum(len(r[0]) for r in inputs)\n",
    "    total_output_chars = sum(len(r[0]) for r in outputs)\n",
    "    \n",
    "    in_tokens = total_input_chars / 4\n",
    "    out_tokens = total_output_chars / 4\n",
    "    \n",
    "    est_cost = (in_tokens/1000 * COST_PER_1K_INPUT) + (out_tokens/1000 * COST_PER_1K_OUTPUT)\n",
    "    \n",
    "    print(f\"1. Total Input Tokens:  {int(in_tokens):,}\")\n",
    "    print(f\"2. Total Output Tokens: {int(out_tokens):,}\")\n",
    "    print(f\"3. Est. Session Cost:   ${est_cost:.6f}\")\n",
    "    \n",
    "    if est_cost > 0.01:\n",
    "        print(\"‚ö†Ô∏è  Alert: Cost exceeding micro-tier budget.\")\n",
    "    else:\n",
    "        print(\"‚úÖ  Status: Highly Efficient (Within budget).\")\n",
    "\n",
    "generate_cost_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683fa31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 33: Containerization Artifacts\n",
    "\n",
    "* **Purpose:** Prepares the code for Cloud deployment.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Generates `requirements.txt` (dependency list).\n",
    "    \n",
    "    * Generates `Dockerfile` (instructions to build the app container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebc805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:34:47.207129Z",
     "iopub.status.busy": "2025-11-29T11:34:47.206795Z",
     "iopub.status.idle": "2025-11-29T11:34:47.216204Z",
     "shell.execute_reply": "2025-11-29T11:34:47.215082Z",
     "shell.execute_reply.started": "2025-11-29T11:34:47.207105Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 33: CONTAINERIZATION ARTIFACTS ---\n",
    "\n",
    "print(\"üì¶ [DEPLOY] Generating Production Container Files...\")\n",
    "\n",
    "# 1. Generate requirements.txt\n",
    "requirements = \"\"\"\n",
    "google-adk>=0.1.0\n",
    "pydantic>=2.0.0\n",
    "pandas\n",
    "matplotlib\n",
    "seaborn\n",
    "\"\"\"\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(requirements.strip())\n",
    "\n",
    "# 2. Generate Dockerfile\n",
    "dockerfile = \"\"\"\n",
    "# Use official lightweight Python image\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Initialize Database & Memory on startup\n",
    "# (In prod, you'd connect to Cloud SQL, but this inits the local db for the container)\n",
    "RUN python -c \"from insightswarm import init_db; init_db()\"\n",
    "\n",
    "# Expose port for Agent Engine or Cloud Run\n",
    "EXPOSE 8080\n",
    "\n",
    "# Start the Agent\n",
    "CMD [\"python\", \"insightswarm.py\"]\n",
    "\"\"\"\n",
    "with open(\"Dockerfile\", \"w\") as f:\n",
    "    f.write(dockerfile.strip())\n",
    "\n",
    "print(\"   - 'requirements.txt' ... Created\")\n",
    "print(\"   - 'Dockerfile' ......... Created\")\n",
    "print(\"\\nüöÄ SYSTEM STATUS: PERFECT.\")\n",
    "print(\"   Your agent has Intelligence, Safety, Memory, Quality Control,\")\n",
    "print(\"   Observability, User Feedback, Cost Tracking, and Deployment Artifacts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9af9d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 34: Production Utilities\n",
    "\n",
    "* **Purpose:** Adds robustness helpers.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * `clean_and_parse_json`: A utility to robustly parse JSON from LLMs (which often include markdown formatting).\n",
    "    \n",
    "    * `cache_result`: A decorator to cache expensive function calls so they don't run twice for the same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813071f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:40:52.819947Z",
     "iopub.status.busy": "2025-11-29T11:40:52.819533Z",
     "iopub.status.idle": "2025-11-29T11:40:52.830241Z",
     "shell.execute_reply": "2025-11-29T11:40:52.829182Z",
     "shell.execute_reply.started": "2025-11-29T11:40:52.819923Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 34: PRODUCTION UTILITIES (Caching & Parsing) ---\n",
    "import functools\n",
    "\n",
    "# 1. Robust JSON Parser (Fixes common LLM formatting errors)\n",
    "def clean_and_parse_json(llm_output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Strips markdown backticks and handles common JSON errors from LLMs.\n",
    "    \"\"\"\n",
    "    # Remove ```json and ``` markers\n",
    "    cleaned = re.sub(r\"```json\\s*|\\s*```\", \"\", llm_output).strip()\n",
    "    # Remove any leading text before the first {\n",
    "    if \"{\" in cleaned:\n",
    "        cleaned = cleaned[cleaned.find(\"{\"):]\n",
    "    # Remove any trailing text after the last }\n",
    "    if \"}\" in cleaned:\n",
    "        cleaned = cleaned[:cleaned.rfind(\"}\")+1]\n",
    "    \n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ö†Ô∏è JSON Parse Failed. Raw output: {llm_output[:50]}...\")\n",
    "        return {}\n",
    "\n",
    "# 2. Caching Decorator (Saves API calls)\n",
    "# In prod, this would use Redis. Here we use Python memory.\n",
    "_memory_cache = {}\n",
    "\n",
    "def cache_result(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Create a unique key based on arguments\n",
    "        key = f\"{func.__name__}:{str(args)}:{str(kwargs)}\"\n",
    "        \n",
    "        if key in _memory_cache:\n",
    "            print(f\"‚ö° [CACHE] Hit! Retrieving result for {func.__name__}...\")\n",
    "            return _memory_cache[key]\n",
    "        \n",
    "        result = func(*args, **kwargs)\n",
    "        _memory_cache[key] = result\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "print(\"‚úÖ Production Utilities (Parser & Cache) Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6828a51",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 35: Upgrading Tools\n",
    "\n",
    "* **Purpose:** Applies the utilities to the agents.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Wraps the SQL and RAG tools with the `@cache_result` decorator.\n",
    "    \n",
    "    * Updates the agent tool lists to use these optimized versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ea091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:46:06.368858Z",
     "iopub.status.busy": "2025-11-29T11:46:06.367653Z",
     "iopub.status.idle": "2025-11-29T11:46:06.376666Z",
     "shell.execute_reply": "2025-11-29T11:46:06.375609Z",
     "shell.execute_reply.started": "2025-11-29T11:46:06.368822Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 35: UPGRADING TOOLS WITH CACHE (FIXED) ---\n",
    "import json\n",
    "\n",
    "# 1. Re-define the base function (to fix NameError if Cell 3 wasn't run)\n",
    "def fetch_business_rules(query: str) -> str:\n",
    "    \"\"\"Retrieves KPIs and Formatting Rules.\"\"\"\n",
    "    return json.dumps({\n",
    "        \"KPIs\": \"Target Revenue: $10M. Target Satisfaction: 4.5.\",\n",
    "        \"FORMAT\": \"Use corporate Hex Colors: #1f77b4 (Blue) for charts.\"\n",
    "    })\n",
    "\n",
    "# 2. Apply Caching Decorator\n",
    "@cache_result\n",
    "def cached_sql_analytics(query: str) -> str:\n",
    "    # Re-use existing logic but now cached\n",
    "    return run_sql_analytics(query)\n",
    "\n",
    "@cache_result\n",
    "def cached_business_rules(query: str) -> str:\n",
    "    return fetch_business_rules(query)\n",
    "\n",
    "# 3. Update the Tool Definitions\n",
    "# We create new FunctionTool instances pointing to the cached versions\n",
    "sql_tool_v2 = FunctionTool(cached_sql_analytics)\n",
    "rag_tool_v2 = FunctionTool(cached_business_rules)\n",
    "\n",
    "# 4. Update the Agents to use V2 Tools\n",
    "# (We update the references in the swarm dynamically)\n",
    "engineer_v2.tools = [sql_tool_v2]\n",
    "analyst_v2.tools = [sql_tool_v2, rag_tool_v2]\n",
    "\n",
    "print(\"‚úÖ Tools Upgraded: SQL and RAG now support Caching.\")\n",
    "print(\"üéâ PROJECT STATUS: 100% COMPLETE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2db406",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Cell 36: The Final Demo\n",
    "\n",
    "* **Purpose:** The \"Money Shot\" - a final, comprehensive run.\n",
    "\n",
    "* **Key Actions:**\n",
    "\n",
    "    * Runs a complex query that requires ALL capabilities: SQL, Logic, Plotting, Caching, and Safety.\n",
    "    \n",
    "    * Displays the final generated chart as proof of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b96989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:46:11.540101Z",
     "iopub.status.busy": "2025-11-29T11:46:11.539790Z",
     "iopub.status.idle": "2025-11-29T11:46:48.053828Z",
     "shell.execute_reply": "2025-11-29T11:46:48.052648Z",
     "shell.execute_reply.started": "2025-11-29T11:46:11.540077Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CELL 36: THE FINAL DEMO (THE MONEY SHOT) ---\n",
    "import time\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 1. Setup a fresh Session for the Demo\n",
    "# We use a timestamp to ensure it's a clean run\n",
    "demo_session_id = f\"demo_video_run_{int(time.time())}\"\n",
    "print(f\"üé¨ ACTION: Starting Final Demo Run (Session: {demo_session_id})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. Register the Session\n",
    "# (Using the latest 'app_v2' or 'app' you defined)\n",
    "await runner_v2.session_service.create_session(\n",
    "    app_name=app_v2.name,\n",
    "    user_id=\"admin\",\n",
    "    session_id=demo_session_id\n",
    ")\n",
    "\n",
    "# 3. The \"All-In-One\" Prompt\n",
    "# This prompt forces the agent to use SQL, Logic, and Plotting tools.\n",
    "demo_prompt = \"\"\"\n",
    "Please perform a deep analysis of the 'East' region.\n",
    "1. Calculate the total revenue and average customer sentiment for this region.\n",
    "2. Identify the top-selling product category there.\n",
    "3. Generate a pie chart showing the revenue distribution of products in the East region.\n",
    "4. Save the chart as 'final_analysis.png'.\n",
    "\"\"\"\n",
    "\n",
    "# 4. Execute\n",
    "async for event in runner_v2.run_async(\n",
    "    user_id=\"admin\",\n",
    "    session_id=demo_session_id,\n",
    "    new_message=types.Content(role=\"user\", parts=[types.Part(text=demo_prompt)])\n",
    "):\n",
    "    if event.content and event.content.parts:\n",
    "        for part in event.content.parts:\n",
    "            if part.text:\n",
    "                print(f\"\\nü§ñ {event.author}:\\n{part.text}\")\n",
    "\n",
    "# 5. Display the Result\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL OUTPUT\")\n",
    "if os.path.exists('final_analysis.png'):\n",
    "    display(Image(filename='final_analysis.png'))\n",
    "    print(\"‚úÖ Chart generated successfully.\")\n",
    "else:\n",
    "    # Fallback to checking dashboard.png if the agent used the default name\n",
    "    if os.path.exists('dashboard.png'):\n",
    "        display(Image(filename='dashboard.png'))\n",
    "        print(\"‚úÖ Chart generated (saved as default 'dashboard.png').\")\n",
    "    else:\n",
    "        print(\"‚ùå Chart not found.\")\n",
    "\n",
    "print(\"‚úÖ Analysis Logic Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87106cfb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.652868,
   "end_time": "2025-11-30T08:12:04.744416",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T08:10:58.091548",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
